// ------------------------------------------------------------------
// Copyright (c) 2017
// The Chinese University of Hong Kong
// Written by Hu Xiaowei
//
// Spatial RNN with identity matrix at four directions 
// ------------------------------------------------------------------
#include <vector>

#include "caffe/layers/irnn_layer.hpp"
#include "caffe/util/math_functions.hpp"

namespace caffe {

template <typename Dtype>  //left up right down
__global__ void IRNNForward(const int nthreads, const Dtype* bottom_data, Dtype* top_left, Dtype* top_up, Dtype* top_right, Dtype* top_down, const int channel, const int height, const int width, const Dtype* weight_data) {
  CUDA_KERNEL_LOOP(index, nthreads) {

     int w = index % width;
     int h = (index / width) % height;
     int c = (index / width / height) % channel;
     int n = index / width / height / channel;

     Dtype temp = 0; 

     //left
     top_left[index] = 0; 
     
     for (int i=width-1; i>=w; i--)
     {
        temp = top_left[index] * weight_data[c] + bottom_data[((n*channel + c)*height + h)*width + i]; //0*channel+c
        top_left[index] = (temp > 0) ? temp : 0; //ReLU: max(x,0)
     }

      
     //up
     top_up[index] = 0;
 
     for (int i=height-1; i>=h; i--)
     {
        temp = top_up[index] * weight_data[channel + c] + bottom_data[((n*channel + c)*height + i)*width + w]; //1*channel+c
        top_up[index] = (temp > 0) ? temp : 0; //ReLU: max(x,0)
     }
     
     
     //right
     top_right[index] = 0;
     
     for (int i=0; i<=w; i++)
     {
        temp = top_right[index] * weight_data[2*channel + c] + bottom_data[((n*channel + c)*height + h)*width + i]; //2*channel+c
        top_right[index] = (temp > 0) ? temp : 0; //ReLU: max(x,0)
     }
     
     
     //down
     top_down[index] = 0; 

     for (int i=0; i<=h; i++)
     {
        temp = top_down[index] * weight_data[3*channel + c] + bottom_data[((n*channel + c)*height + i)*width + w]; //3*channel+c
        top_down[index] = (temp > 0) ? temp : 0; //ReLU: max(x,0)
    
     }

     //printf("ori: %f, left: %f, up: %f, right: %f, down: %f, n: %d, c: %d, h:%d, w:%d\n",bottom_data[index], top_left[index], top_up[index], top_right[index], top_down[index],n,c,h,w);
  }
}

template <typename Dtype>
__global__ void IRNNBackward(const int nthreads, Dtype* bottom_diff, const Dtype* top_left, const Dtype* top_up, const Dtype* top_right, const Dtype* top_down, const Dtype* top_left_data, const Dtype* top_up_data, const Dtype* top_right_data, const Dtype* top_down_data, const int channel, const int height, const int width, const Dtype* weight_data) {
  CUDA_KERNEL_LOOP(index, nthreads) {
     
     int w = index % width;
     int h = (index / width) % height;
     int c = (index / width / height) % channel;
     int n = index / width / height / channel;

     Dtype diff_right = 0;
     Dtype diff_left = 0;
     Dtype diff_down = 0;
     Dtype diff_up = 0;


     //right 
     for (int i=width-1; i>=w; i--)
     {
        diff_right *= weight_data[2*channel + c];
        diff_right += (top_right_data[((n*channel + c)*height + h)*width + i]==0)? 0 : top_right[((n*channel + c)*height + h)*width + i];
     }
 

     //left 
     for (int i=0; i<=w; i++)
     {  
        diff_left *= weight_data[c];
        diff_left += (top_left_data[((n*channel + c)*height + h)*width + i]==0)? 0 : top_left[((n*channel + c)*height + h)*width + i];
     }
     

     //down 
     for (int i=height-1; i>=h; i--)
     {
        diff_down *= weight_data[3*channel + c];
        diff_down += (top_down_data[((n*channel + c)*height + i)*width + w]==0)? 0 : top_down[((n*channel + c)*height + i)*width + w];
     }
     
     
     //up
     for (int i=0; i<=h; i++)
     {  
        diff_up *= weight_data[channel + c];
        diff_up += (top_up_data[((n*channel + c)*height + i)*width + w]==0)? 0 : top_up[((n*channel + c)*height + i)*width + w];
     }

     bottom_diff[index] = diff_right + diff_left + diff_down + diff_up;

     //printf("ori_diff: %f, left: %f, up: %f, right: %f, down: %f, n: %d, c: %d, h:%d, w:%d\n",bottom_diff[index], top_left[index], top_up[index], top_right[index], top_down[index],n,c,h,w);
  }
}

template <typename Dtype>
__global__ void IRNNParamBackward(const int n, const Dtype* top_left, const Dtype* top_up, const Dtype* top_right, const Dtype* top_down, const Dtype* top_left_data, const Dtype* top_up_data, const Dtype* top_right_data, const Dtype* top_down_data, const int channel, const int height, const int width, const Dtype* weight_data, Dtype* weight_diff, int batch_num, const Dtype* bottom_data) {
  CUDA_KERNEL_LOOP(index, n) {
  
  int dir = index / channel;
  int c = index % channel;

  switch (dir)
  {
    Dtype diff;

    case 0: // left 
      diff = 0;
      for (int i=0; i<batch_num; i++)
      {
          for (int j=0; j<height; j++)
          {
              for (int k=0; k<width; k++)
              {
                 Dtype diff_temp = 0;
                 float acc_weight = 1;
                 for (int m=k+1; m<width; m++)
                 {  
                     if (top_left_data[((i*channel + c)*height + j)*width + m]==0)
                     { 
                        break;
                     }
                     diff_temp += (m-k)*acc_weight*top_left[((i*channel + c)*height + j)*width + m];
                     acc_weight *= weight_data[c];
                     
                 }
                 diff += diff_temp*bottom_data[((i*channel + c)*height + j)*width + k];
              }
          }
      }
      weight_diff[c] = diff;
      
      //printf("Dir:%d, c:%d, wight_diff[c]:%f\n",dir,c,diff);
    break;

    case 1: // up
      diff = 0;
      for (int i=0; i<batch_num; i++)
      {
          for (int j=0; j<height; j++)
          {
              for (int k=0; k<width; k++)
              {
                 Dtype diff_temp = 0;
                 float acc_weight = 1;
                 for (int m=j+1; m<height; m++)
                 {  
                     if (top_up_data[((i*channel + c)*height + m)*width + k]==0)
                     { 
                        break;
                     }
                     diff_temp += (m-j)*acc_weight*top_up[((i*channel + c)*height + m)*width + k];
                     acc_weight *= weight_data[channel + c];
                     
                 }
                 diff += diff_temp*bottom_data[((i*channel + c)*height + j)*width + k];
              }
          }
      }
      weight_diff[channel + c] = diff;
      //printf("Dir:%d, c:%d, wight_diff[channel + c]:%f\n",dir,c,diff);
    break;

    case 2: // right
      diff = 0;
      for (int i=0; i<batch_num; i++)
      {
          for (int j=0; j<height; j++)
          {
              for (int k=0; k<width; k++)
              {
                 Dtype diff_temp = 0;
                 float acc_weight = 1;
                 for (int m=k-1; m>=0; m--)
                 {  
                     if (top_right_data[((i*channel + c)*height + j)*width + m]==0)
                     { 
                        break;
                     }
                     diff_temp += (k-m)*acc_weight*top_right[((i*channel + c)*height + j)*width + m];
                     acc_weight *= weight_data[2*channel + c];
                     
                 }
                 diff += diff_temp*bottom_data[((i*channel + c)*height + j)*width + k];
              }
          }
      }
      weight_diff[2*channel + c] = diff;
      //printf("Dir:%d, c:%d, wight_diff[2*channel + c]:%f\n",dir,c,diff);
    break;

    case 3: // down
      diff = 0;
      for (int i=0; i<batch_num; i++)
      {
          for (int j=0; j<height; j++)
          {
              for (int k=0; k<width; k++)
              {
                 Dtype diff_temp = 0;
                 float acc_weight = 1;
                 for (int m=j-1; m>=0; m--)
                 {  
                     if (top_down_data[((i*channel + c)*height + m)*width + k]==0)
                     { 
                        break;
                     }
                     diff_temp += (j-m)*acc_weight*top_down[((i*channel + c)*height + m)*width + k];
                     acc_weight *= weight_data[3*channel + c];
                     
                 }
                 diff += diff_temp*bottom_data[((i*channel + c)*height + j)*width + k];
              }
          }
      }
      weight_diff[3*channel + c] = diff;
      //printf("Dir:%d, c:%d, wight_diff[3*channel + c]:%f\n",dir,c,diff);
    break;
   
    default: break;
  }  
 }
}

template <typename Dtype>
void IRNNLayer<Dtype>::Forward_gpu(const vector<Blob<Dtype>*>& bottom,
      const vector<Blob<Dtype>*>& top) {
  
  int count = bottom[0]->count();
 
  Dtype* top_data[4];

  for (int i=0; i<4; i++)
  {
      top_data[i] = top[i]->mutable_gpu_data();
  }

  const Dtype* bottom_data = bottom[0]->gpu_data();
  const Dtype* weight_data = this->blobs_[0]->gpu_data();

  IRNNForward<Dtype>  
        <<<CAFFE_GET_BLOCKS(count), CAFFE_CUDA_NUM_THREADS>>>(count, bottom_data, top_data[0], top_data[1], top_data[2], top_data[3], channels_, height_, width_, weight_data);
  CUDA_POST_KERNEL_CHECK;

}

template <typename Dtype>
void IRNNLayer<Dtype>::Backward_gpu(const vector<Blob<Dtype>*>& top,
      const vector<bool>& propagate_down, const vector<Blob<Dtype>*>& bottom) {

  int count = bottom[0]->count();

  const Dtype* top_left = top[0]->gpu_diff();
  const Dtype* top_up = top[1]->gpu_diff();
  const Dtype* top_right = top[2]->gpu_diff();
  const Dtype* top_down = top[3]->gpu_diff();

  const Dtype* top_left_data = top[0]->gpu_data();
  const Dtype* top_up_data = top[1]->gpu_data();
  const Dtype* top_right_data = top[2]->gpu_data();
  const Dtype* top_down_data = top[3]->gpu_data();

  Dtype* bottom_diff = bottom[0]->mutable_gpu_diff();
  const Dtype* weight_data = this->blobs_[0]->gpu_data();

  IRNNBackward<Dtype>  // NOLINT_NEXT_LINE(whitespace/operators)
        <<<CAFFE_GET_BLOCKS(count), CAFFE_CUDA_NUM_THREADS>>>(count, bottom_diff, top_left, top_up, top_right, top_down, top_left_data, top_up_data, top_right_data, top_down_data, channels_, height_, width_, weight_data);
  CUDA_POST_KERNEL_CHECK;

  
  
  if (!weight_fixed)
  {
    int cdim = 4*channels_;
    Dtype* weight_diff = this->blobs_[0]->mutable_gpu_diff();
    const Dtype* bottom_data = bottom[0]->gpu_data();
    int batch_num = bottom[0]->shape(0);

    IRNNParamBackward<Dtype><<<CAFFE_GET_BLOCKS(cdim), CAFFE_CUDA_NUM_THREADS>>>(cdim, top_left, top_up, top_right, top_down, top_left_data, top_up_data, top_right_data, top_down_data, channels_, height_, width_, weight_data, weight_diff, batch_num, bottom_data);
    CUDA_POST_KERNEL_CHECK;
  }
}

INSTANTIATE_LAYER_GPU_FUNCS(IRNNLayer);

}  // namespace caffe
